---
title: "project3"
format: md
---

## Objective

Can we predict a playerâ€™s performance/worth in an upcoming season based on their previous performance stats and other metrics?

## Description of Data

We have data from qualified (300+ PAs) batters in each season from 2015 to 2024. Most of it is from Statcast but we also added the columns WAR (wins above replacement), R (runs), OPS+ (on-base plus slugging), rOBA (run-out batting average), and Rbat+ from Baseball Reference. We will predict a player's WAR in an upcoming season given their previous stats and stats from all other MLB players. The most important factors in this prediction will be WAR, Age, OPS (on-base plus slugging), xBA (expected batting average), Barrel%, K%, BB%, Rbat+ (weighted runs created +), and HR (homeruns).

## Exploratory Data Analysis

Data cleaning (details listed in Project 2/eda.qmd):

```{python}
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr

def concat_statcast(input1, input2, output):
  try:
    df1 = pd.read_csv(input1)
    df2 = pd.read_csv(input2)
    combined_df = pd.concat([df1, df2], ignore_index=True)
    combined_df.to_csv(output, index=False)
  except:
    print("file not found error")
    
input1 = "Statcast.csv"
input2 = "Statcast_2020.csv"
output = "Complete_Statcast.csv"
concat_statcast(input1, input2, output)

def merge_data(input3, input4, output, columns):
  try:
    df1 = pd.read_csv(input3)
    df1['Player'] = df1['last_name, first_name'].str.split(', ').str[::-1].str.join(' ')
    all_years_df = []
    for i in input4:
      filename = f'{i}.csv'
      df2 = pd.read_csv(filename, skiprows=4, skipfooter=3, engine='python')
      df2['year'] = i 
      df2['Player'] = df2['Player'].str.replace(r'[*#]', '', regex=True).str.strip()
      df2_subset = df2[['Player', 'year'] + columns]
      all_years_df.append(df2_subset)
    combined_df2 = pd.concat(all_years_df, ignore_index=True)
    merged_df = pd.merge(df1, combined_df2, on=['Player', 'year'], how='inner')
    merged_df.to_csv(output, index=False)
    print(merged_df.info)
  except FileNotFoundError:
    print("file not found error")
    
input3 = 'Complete_Statcast.csv'
input4 = range(2015, 2025)
columns = ['WAR', 'R', 'OPS+', 'rOBA', 'Rbat+']
output = "Complete_Data.csv"
merge_data(input3, input4, output, columns)
complete_dataset = pd.read_csv(output)

key_columns = ['xba', 'barrel_batted_rate', 'player_age', 'WAR', 'k_percent', 'bb_percent', 'on_base_plus_slg', 'Rbat+']
```

### Univariate Analysis (Histograms)

```{python}
# Univariate Analysis
print(data[key_columns].describe())

# Histograms
plt.figure(figsize=(16, 12))
for i, col in enumerate(key_columns, 1):
    plt.subplot(3, 3, i)
    sns.histplot(data[col], kde=True, bins=30)
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
plt.tight_layout()
plt.show()
plt.close()
```

We can see that most of the data is either centered or skewed left.

### Bivariate Analysis (Correlation)

```{python}
print(data[key_columns].corr())

plt.figure(figsize=(12, 8))
# xBA vs WAR
plt.subplot(2, 2, 1)
sns.scatterplot(x='xba', y='WAR', data=data)
plt.title('xBA vs WAR')
# Rbat+ vs WAR
plt.subplot(2, 2, 4)
sns.scatterplot(x='Rbat+', y='WAR', data=data)
plt.title('Rbat+ vs WAR')
plt.tight_layout()
plt.show()
plt.close()
```

We can see that xBA vs WAR and Rbat+ vs WAR are somewhat positively correlated.

### Multivariate Analysis (Pairplot)

```{python}
sns.pairplot(data[key_columns], diag_kind='kde', corner=True)
plt.suptitle('Pair Plot of Key Variables')
plt.show()
plt.close()
```

We can see that for every plot most of the data points are clustered in a small area, with a few data points around that cluster. We can also see that the plots we expect to see positive correlation in such as WAR vs xBA, OPS vs BB%, etc. are indeed somewhat positively correlated while there are others that do not seem too correlated.

The resulting png files are in Project 1 -> Data.

### Modeling

We will be using Recurrent Neural Networks as our main model. Before we start modeling, however, we must clean the data so we have sequences of seasons for each player. 

Import necessary packages

```{python}
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.callbacks import ReduceLROnPlateau
import tensorflow as tf
```

Create the model.

```{python}
def rnn_prediction(input, output, target, key_cols, sequence_length):
  # Sort by Player and Season
  complete_dataset = complete_dataset.sort_values(['Player', 'year'], ascending=[True, True])
  # Filter players with >3 seasons because we need a sequence of seasons from each single player
  season_counts = complete_dataset.groupby('Player')['year'].nunique()
  valid_players = season_counts[season_counts > sequence_length].index
  # Create sequences
  X = []
  y = []
  player_years = []
  
  for player in valid_players:
      player_data = df[df['Player'] == player]
      feature_data = player_data[key_cols].values
      target_data = player_data[target].values
      years = player_data['year'].values
  
      for i in range(len(feature_data) - sequence_length):
          sequence = feature_data[i:i + sequence_length]
          if sequence.shape != (sequence_length, 8):
              continue
          X.append(sequence)
          y.append(target_data[i + sequence_length])
          player_years.append((player, years[i + sequence_length]))
    
    X = np.array(X)
    y = np.array(y)
    
    # Scale features and target
    scaler_X = StandardScaler()
    scaler_y = StandardScaler()
    X_reshaped = X.reshape(-1, 8)
    X_scaled = scaler_X.fit_transform(X_reshaped).reshape(X.shape)
    y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()
    
    # Split data to train and test data
    train_idx = int(0.8 * len(X))
    X_train, X_test = X_scaled[:train_idx], X_scaled[train_idx:]
    y_train, y_test = y_scaled[:train_idx], y_scaled[train_idx:]
    test_player_years = player_years[train_idx:]
    
    # RNN model (Long Short-Term Memory, LSTM)
    model = Sequential([LSTM(50, input_shape=(sequence_length, 8), return_sequences=False),
                        Dense(25, activation='relu'), Dense(1)
                       ])
    model.compile(optimizer='adam', loss='mse')
    
    # Train model
    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0, validation_split=0.2)
    
    # Predict
    y_pred_scaled = model.predict(X_test)
    y_pred = scaler_y.inverse_transform(y_pred_scaled).flatten()
    y_test_orig = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()
    
    # Evaluate RMSE and r^2
    rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))
    r2 = r2_score(y_test_orig, y_pred)
    
    # Save predictions
    test_df = pd.DataFrame({
        'Player': [py[0] for py in test_player_years],
        'Year': [py[1] for py in test_player_years],
        'Actual_WAR': y_test_orig,
        'Predicted_WAR': y_pred
    })
    test_df.to_csv(output, index=False)
    
    return model, test_df, rmse, r2
  
# Run the code
input = "Complete_Data.csv"
output1 = "Predictions_rnn.csv"
# we take the most important stats
key_columns = ['xba', 'barrel_batted_rate', 'player_age', 'batting_avg', 'k_percent', 'bb_percent', 'on_base_plus_slg', 'Rbat+'] 
# we will predict a player's WAR (wins above replacement)
target = "WAR"
sequence_length = 3 # we can choose this and this could be longer but we don't have enough data for it
model, df, rmse, r2 = rnn_prediction(input, output1, target, key_columns, sequence_length)
print(f"RMSE: {rmse:.3f}")
print(f"R^2: {r2:.3f}")
```

We get a RMSE of around 1.7 and r^2 of around 0.25. These are not the best numbers but considering that a player's WAR can be very unpredictable it is not the worst either. However, I wanted a better model so I asked AI what the best model for this situation would be and it told me Random Forests. So we will also implement a random forest and compare with LSTM.

```{python}
def rf_prediction(input, output, target, key_cols):
    # Load and sort data
    df = pd.read_csv(input_path).sort_values(['Player', 'year']).reset_index(drop=True)

    if target_col not in df.columns:
        raise ValueError(f"Target column '{target}' not found in the dataset.")

    # Add lagged versions of the target. Lagged versions are the previous years' WAR values
    df['lag1'] = df.groupby('Player')[target].shift(1)
    df['lag2'] = df.groupby('Player')[target].shift(2)
    df['lag3'] = df.groupby('Player')[target].shift(3)

    X = df[all_features]
    y = df[target]

    # Scale input features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Preserve indices for labeling predictions later
    df['row_idx'] = df.index
    X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(
        X_scaled, y, df['row_idx'], test_size=0.2
    )

    # Train the random forest model
    model = RandomForestRegressor(n_estimators=200, max_depth=10)
    model.fit(X_train, y_train)

    # Predict on test set
    y_pred = model.predict(X_test)

    # Evaluate performance
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)

    # Create prediction DataFrame
    predictions = df.loc[idx_test].copy()
    predictions[f'Predicted_{target_col}'] = y_pred
    predictions.to_csv(output_path, index=False)

    return model, predictions, rmse, r2
```

We get a RMSE of around 1.3 and r^2 of around 0.5. These numbers are significantly better than the previous 1.7 and 0.25 of the LSTM, suggesting that Random Forest is the better model for this project than RNN/LSTM. 1.3 is still fairly high considering that WAR is usually within the range [-2, 10] but with how real world sports can be, 1.3 is not a bad error. 

We can increase r^2 to up to around 0.65 just by changing the max_depth to 6 instead of 10. 

### Results

From Recurrent Neural Networks (RNN, specifically Long Short-Term Memory), we got a root mean squared error (RMSE) of around 1.7 and a r^2 value of around 0.25. These numbers represent a model that is showing some signs of picking up patterns within the data but has lots of area for improvement. We could probably improve this model to make it more accurate in predictions but this might not be as good of a model as I initially thought for this project because not all players have the same developments; some players might be great in their late 20s and fall off dramatically after while others are consistently good throughout a long career but never great. 

Pivoting to Random Forest Regressor model, we were able to get a RMSE of around 1.3 and r^2 of around 0.5. These numbers are significant improvements over the numbers we got from the LSTM model. There can be a few explanations for this phenomenon. Random Forests deal with noisy sequences better than LSTMs do. The data we have can be noisy because of a few factors: our data includes the shortened 2020 COVID season in which there were only 60 games played instead of the usual 162, which can lead to more outliers; some players may experience injury, slumps, or another player at the same position may take over many of their play-time; and we do not have enough player data for an LSTM model to reach its full potential. 

Original Question: "Can we predict a playerâ€™s performance/worth in an upcoming season based on their previous performance stats and other metrics?"
A 0.65 r^2 value indicates that we were able to build a moderately reliable model that can predict WAR in any given season for a player given their previous years' statistics. Considering the inherent randomness of real-world sports, this number is solid. There may be ways to improve this model and make it more accurate in predicting a player's WAR, but even the best models are not the best predictors of real-world data. 